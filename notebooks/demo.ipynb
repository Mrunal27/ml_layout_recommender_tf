{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dc97b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow faiss-cpu pillow pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766ce2c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import faiss\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f59bd0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Mrunal27/ml_layout_recommender_tf.git\n",
    "%cd ml_layout_recommender_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c5c13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('./src')\n",
    "sys.path.append('./fastapi_app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745f3e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from models import build_embedding_model\n",
    "from model_utils import LayoutRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775f958",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('uploads', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909eb81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "path_to_zip = tf.keras.utils.get_file('flower_photos.tgz', origin=dataset_url, extract=True)\n",
    "extracted_dir = os.path.join(os.path.dirname(path_to_zip), 'flower_photos')\n",
    "\n",
    "image_files = glob.glob(os.path.join(extracted_dir, \"*/*.jpg\"))[:20]\n",
    "print(f\"Number of images for demo: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e37d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'image_path': image_files})\n",
    "df.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1286438",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = build_embedding_model(embedding_dim=128)\n",
    "embedding_model.save('models/embedding_extractor.keras')  # Safe save\n",
    "embedding_model = tf.keras.models.load_model('models/embedding_extractor.keras')  # Load back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157d911",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for img_path in df['image_path']:\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224,224))\n",
    "    img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
    "    emb = embedding_model(np.expand_dims(img.numpy(), axis=0))\n",
    "    embeddings.append(emb.numpy()[0])\n",
    "embeddings = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b825d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings.astype('float32'))\n",
    "faiss.write_index(index, 'models/gallery.index')\n",
    "np.save('models/gallery_paths.npy', np.array(df['image_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb454449",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "recommender = LayoutRecommender(\n",
    "    embedding_model_dir='models/embedding_extractor.keras',\n",
    "    index_path='models/gallery.index',\n",
    "    gallery_paths_path='models/gallery_paths.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11221ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query_img = image_files[0]  # pick first image as query\n",
    "top_k = 3\n",
    "recommended_paths = recommender.recommend(query_img, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edad705",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def show_images(query, recs):\n",
    "    fig, axes = plt.subplots(1, len(recs)+1, figsize=(12,4))\n",
    "    axes[0].imshow(Image.open(query))\n",
    "    axes[0].set_title('Query')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    for i, path in enumerate(recs):\n",
    "        axes[i+1].imshow(Image.open(path))\n",
    "        axes[i+1].set_title(f'Rec {i+1}')\n",
    "        axes[i+1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_images(query_img, recommended_paths)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
